import SwiftUI
import AVFoundation
import SwiftData
import CoreLocation
import UIKit
import Foundation
import CoreImage
import CoreImage.CIFilterBuiltins
import MetalKit

struct CameraView: View {
    let preset: FilmPreset
    @Environment(\.dismiss) private var dismiss
    @Environment(\.modelContext) private var modelContext
    @Query(sort: \Roll.createdAt, order: .reverse) private var rolls: [Roll]
    @Query(sort: \Photo.timestamp, order: .reverse) private var allPhotos: [Photo]
    @StateObject private var cameraManager: CameraManager
    @State private var showFlash = false
    @State private var exposuresRemaining: Int = 27
    @State private var currentRoll: Roll?
    @State private var isCapturing = false
    @State private var lastCapturedPhoto: Photo?
    @State private var lastPhotoThumbnail: UIImage?
    @State private var showingGallery = false

    init(preset: FilmPreset) {
        self.preset = preset
        _cameraManager = StateObject(wrappedValue: CameraManager(preset: preset))
    }

    var body: some View {
        ZStack {
            // èƒŒæ™¯ï¼šè´¨æ„Ÿé»‘è‰²ï¼ˆå¤šå±‚æ¸å˜å åŠ ï¼‰
            ZStack {
                LinearGradient(colors: [Color(red: 0.06, green: 0.06, blue: 0.06), Color.black], startPoint: .top, endPoint: .bottom)
                RadialGradient(gradient: Gradient(colors: [Color.white.opacity(0.06), .clear]), center: .top, startRadius: 0, endRadius: 400)
                LinearGradient(colors: [Color.clear, Color.white.opacity(0.04)], startPoint: .topLeading, endPoint: .bottomTrailing)
            }
            .ignoresSafeArea()

            VStack(spacing: 0) {
                // é¡¶éƒ¨ï¼šå·¦ä¸Šè¿”å›ï¼ˆæ”¾å¤§ï¼‰ + å³ä¸Šå‰©ä½™æ¬¡æ•°
                HStack(alignment: .center) {
                    Button(action: { dismiss() }) {
                        Image(systemName: "xmark")
                            .font(.system(size: 18, weight: .bold))
                            .foregroundStyle(.white)
                            .frame(width: 40, height: 40)
                            .background(Color.white.opacity(0.10))
                            .clipShape(Circle())
                    }

                    Spacer()

                    HStack(spacing: 6) {
                        Text("EXP")
                            .font(.system(size: 11, weight: .bold))
                            .foregroundStyle(.white.opacity(0.85))
                        Text("\(exposuresRemaining)")
                            .font(.system(size: 18, weight: .heavy))
                            .monospacedDigit()
                            .foregroundStyle(.white)
                    }
                    .padding(.horizontal, 10)
                    .padding(.vertical, 8)
                    .background(Color.white.opacity(0.08))
                    .clipShape(RoundedRectangle(cornerRadius: 8, style: .continuous))
                }
                .padding(.horizontal, 16)
                .padding(.top, 12)

                Spacer(minLength: 8)

                // ä¸­é—´é¢„è§ˆåŒºï¼š3:4 å›ºå®šå–æ™¯æ¡†
                GeometryReader { _ in
                    RealtimePreviewView(manager: cameraManager, preset: preset)
                        .clipShape(RoundedRectangle(cornerRadius: 16, style: .continuous))
                        .shadow(color: .black.opacity(0.5), radius: 12, x: 0, y: 8)
                }
                .aspectRatio(3/4, contentMode: .fit)
                .padding(.horizontal, 16)

                Spacer(minLength: 8)

                // åº•éƒ¨æ§åˆ¶åŒºï¼šå·¦ä¾§é—ªå…‰ç¯ + ä¸­é—´å¿«é—¨ + å³ä¾§ç¼©ç•¥å›¾
                HStack(alignment: .center) {
                    // å·¦ä¾§é—ªå…‰ç¯æŒ‰é’®
                    Button(action: {
                        UIImpactFeedbackGenerator(style: .light).impactOccurred()
                        cameraManager.toggleFlashMode()
                    }) {
                        let isOn = cameraManager.flashMode == .on
                        Image(systemName: isOn ? "bolt.fill" : "bolt.slash.fill")
                            .font(.system(size: 18, weight: .semibold))
                            .foregroundStyle(isOn ? Color.black : Color.white.opacity(0.8))
                            .frame(width: 44, height: 44)
                            .background(isOn ? Color.yellow : Color.white.opacity(0.12))
                            .clipShape(Circle())
                    }
                    .buttonStyle(.plain)

                    Spacer()

                    // ä¸­é—´å¿«é—¨æŒ‰é’®ï¼ˆç™½è‰²åœ†ç¯è®¾è®¡ï¼‰
                    Button(action: { capturePhoto() }) {
                        ZStack {
                            // å¤–åœˆç™½è‰²ç¯
                            Circle()
                                .stroke(Color.white, lineWidth: 4)
                                .frame(width: 72, height: 72)
                            // å†…åœˆæŒ‰é’®
                            Circle()
                                .fill(Color.white)
                                .frame(width: 60, height: 60)
                                .scaleEffect(isCapturing ? 0.9 : 1.0)
                                .animation(.easeInOut(duration: 0.1), value: isCapturing)
                        }
                        .shadow(color: .black.opacity(0.3), radius: 6, x: 0, y: 4)
                    }
                    .buttonStyle(.plain)

                    Spacer()

                    // å³ä¾§æœ€è¿‘ç…§ç‰‡ç¼©ç•¥å›¾
                    Button(action: { showingGallery = true }) {
                        if let lastPhoto = lastCapturedPhoto, let thumb = lastPhotoThumbnail {
                            Image(uiImage: thumb)
                                .resizable()
                                .aspectRatio(contentMode: .fill)
                                .frame(width: 44, height: 44)
                                .clipShape(RoundedRectangle(cornerRadius: 8, style: .continuous))
                                .overlay(
                                    RoundedRectangle(cornerRadius: 8, style: .continuous)
                                        .stroke(Color.white.opacity(0.3), lineWidth: 1)
                                )
                        } else {
                            Image(systemName: "photo.on.rectangle")
                                .font(.system(size: 18, weight: .medium))
                                .foregroundStyle(Color.white.opacity(0.6))
                                .frame(width: 44, height: 44)
                                .background(Color.white.opacity(0.12))
                                .clipShape(RoundedRectangle(cornerRadius: 8, style: .continuous))
                        }
                    }
                    .buttonStyle(.plain)
                }
                .padding(.horizontal, 40)
                .padding(.bottom, 20)
            }

            // å¿«é—¨é—ªå…‰æ•ˆæœ
            if showFlash {
                Color.white
                    .ignoresSafeArea()
                    .opacity(0.7)
            }
        }
        .statusBarHidden(true)
        .onAppear {
            // é”å®šä¸ºç«–å±
            OrientationManager.shared.lockOrientation(.portrait)
            // å¼ºåˆ¶æ—‹è½¬åˆ°ç«–å±
            if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene {
                windowScene.requestGeometryUpdate(.iOS(interfaceOrientations: .portrait))
            }

            FilmProcessor.shared.preload(preset: preset)
            cameraManager.requestCameraPermission()
            prepareCurrentRoll()
            updateExposuresRemaining()
            loadLastPhotoThumbnail()
        }
        .onDisappear {
            // è§£é”æ–¹å‘
            OrientationManager.shared.unlockOrientation()
            cameraManager.stopLocationServices()
        }
        .fullScreenCover(isPresented: $showingGallery) {
            GalleryView()
        }
        .onChange(of: allPhotos.count) { _, _ in
            loadLastPhotoThumbnail()
        }
    }

    private func loadLastPhotoThumbnail() {
        guard let photo = allPhotos.first else {
            lastCapturedPhoto = nil
            lastPhotoThumbnail = nil
            return
        }
        lastCapturedPhoto = photo
        Task {
            let thumb = await ImageLoader.shared.loadThumbnail(for: photo, maxPixel: 88)
            await MainActor.run {
                lastPhotoThumbnail = thumb
            }
        }
    }
    
    private func capturePhoto() {
        // é˜²æ­¢é‡å¤æ‹æ‘„
        guard !isCapturing else { return }

        // ç«‹å³è§¦å‘è§¦è§‰åé¦ˆ
        UIImpactFeedbackGenerator(style: .medium).impactOccurred()

        // å¿«é—¨æŒ‰å‹åŠ¨ç”» + é—ªå…‰æ•ˆæœ
        Task { @MainActor in
            isCapturing = true
            try? await Task.sleep(nanoseconds: 80_000_000) // 0.08s æŒ‰å‹æ•ˆæœ

            withAnimation(.easeOut(duration: 0.08)) {
                showFlash = true
            }
            try? await Task.sleep(nanoseconds: 100_000_000) // 0.1s é—ªå…‰
            withAnimation(.easeIn(duration: 0.1)) {
                showFlash = false
            }

            isCapturing = false
        }

        // è§¦å‘æ‹æ‘„ï¼ˆå›è°ƒä»…å¤„ç†æ•°æ®ï¼‰
        let currentPreset = preset
        let manager = cameraManager
        let context = modelContext

        cameraManager.capturePhoto { imageData in
            guard let data = imageData else { return }

            // åå°å¤„ç†ç®¡é“ï¼ˆä¸é˜»å¡ UIï¼‰
            Task.detached(priority: .userInitiated) {
                // iOS 18 ä¼˜åŒ–ï¼šå¹¶å‘å¤„ç† LUT + GPSï¼ˆèŠ‚çœ ~500msï¼‰
                async let processedData = FilmProcessor.shared.applyLUTPreservingMetadata(
                    imageData: data,
                    preset: currentPreset,
                    outputQuality: 0.95,
                    location: await manager.cachedOrFreshLocation()
                )
                async let location = manager.cachedOrFreshLocation()

                // ç­‰å¾…å¹¶å‘ä»»åŠ¡å®Œæˆ
                let (finalData, finalLoc) = await (processedData ?? data, location)

                // ä¸»çº¿ç¨‹ä¿å­˜ï¼ˆä½¿ç”¨ nonisolated ä¸Šä¸‹æ–‡é¿å… Sendable è­¦å‘Šï¼‰
                await MainActor.run {
                    Self.savePhotoToContext(
                        imageData: finalData,
                        preset: currentPreset,
                        location: finalLoc,
                        context: context
                    )
                }
            }
        }
    }

    @MainActor
    private static func savePhotoToContext(
        imageData: Data,
        preset: FilmPreset,
        location: CLLocation?,
        context: ModelContext
    ) {
        let newPhoto = Photo(imageData: imageData, filmPresetName: preset.rawValue)
        if let loc = location {
            newPhoto.latitude = loc.coordinate.latitude
            newPhoto.longitude = loc.coordinate.longitude
            newPhoto.altitude = loc.altitude
            newPhoto.locationTimestamp = loc.timestamp
        }

        // æŸ¥æ‰¾æˆ–åˆ›å»ºå½“å‰èƒ¶å·
        let descriptor = FetchDescriptor<Roll>(
            sortBy: [SortDescriptor(\.createdAt, order: .reverse)]
        )
        let allRolls = (try? context.fetch(descriptor)) ?? []
        let activeRolls = allRolls.filter { $0.presetName == preset.rawValue && !$0.isCompleted }

        let roll = activeRolls.first ?? {
            let newRoll = Roll(preset: preset, capacity: 27)
            context.insert(newRoll)
            return newRoll
        }()

        newPhoto.roll = roll
        context.insert(newPhoto)

        do {
            try context.save()
            print("ğŸ“¸ Photo saved successfully")
            if roll.isCompleted {
                print("ğŸï¸ èƒ¶å·å·²æ‹å®Œ \(roll.capacity) å¼ ï¼Œè‡ªåŠ¨å®Œæˆ")
            }
        } catch {
            print("âŒ Failed to save photo: \(error)")
        }
    }

    private func prepareCurrentRoll() {
        if let active = rolls.first(where: { $0.presetName == preset.rawValue && !$0.isCompleted }) {
            currentRoll = active
        } else {
            currentRoll = createOrFetchActiveRoll()
        }
    }

    private func createOrFetchActiveRoll() -> Roll {
        if let active = rolls.first(where: { $0.presetName == preset.rawValue && !$0.isCompleted }) {
            return active
        }
        let newRoll = Roll(preset: preset, capacity: 27)
        modelContext.insert(newRoll)
        do { try modelContext.save() } catch { print("ä¿å­˜æ–°èƒ¶å·å¤±è´¥: \(error)") }
        return newRoll
    }

    private func updateExposuresRemaining() {
        if let active = rolls.first(where: { $0.presetName == preset.rawValue && !$0.isCompleted }) {
            exposuresRemaining = active.exposuresRemaining
            currentRoll = active
            if active.isCompleted && active.completedAt == nil {
                active.completedAt = Date()
            }
        } else if let current = currentRoll {
            exposuresRemaining = current.exposuresRemaining
        } else {
            exposuresRemaining = 27
        }
    }
    
    // å›ºå®šç„¦è·ä¸º 35mmï¼Œä¸æä¾› UI è°ƒæ•´
    @MainActor
    private func setFocus(at point: CGPoint) {
        // ä¿ç•™å ä½ï¼ˆå·²æ”¹ç”± GeometryReader å†…éƒ¨è®¡ç®—è®¾å¤‡åæ ‡å¹¶è°ƒç”¨ï¼‰
        cameraManager.setFocusAndExposure(normalizedPoint: CGPoint(x: 0.5, y: 0.5))
    }
}

    

// ç›¸æœºé¢„è§ˆè§†å›¾
struct CameraPreviewView: UIViewRepresentable {
    let session: AVCaptureSession
    
    func makeUIView(context: Context) -> UIView {
        let view = UIView()
        view.backgroundColor = UIColor.black
        
        let previewLayer = AVCaptureVideoPreviewLayer(session: session)
        previewLayer.videoGravity = .resizeAspect // ä¸4:3å®¹å™¨ä¿æŒä¸€è‡´ä¸è£åˆ‡
        
        view.layer.addSublayer(previewLayer)
        
        // å­˜å‚¨é¢„è§ˆå±‚ä»¥ä¾¿åç»­æ›´æ–°
        view.layer.setValue(previewLayer, forKey: "previewLayer")
        
        return view
    }
    
    func updateUIView(_ uiView: UIView, context: Context) {
        // æ›´æ–°é¢„è§ˆå±‚çš„frameä»¥åŒ¹é…è§†å›¾çš„è¾¹ç•Œ
        if let previewLayer = uiView.layer.value(forKey: "previewLayer") as? AVCaptureVideoPreviewLayer {
            DispatchQueue.main.async {
                previewLayer.frame = uiView.bounds
            }
        }
    }
}

// ç›¸æœºç®¡ç†å™¨
// é—ªå…‰ç¯æ¨¡å¼æšä¸¾
enum FlashMode: String, CaseIterable {
    case on = "on" 
    case off = "off"
    
    var displayName: String {
        switch self {
        case .on: return "å¼€å¯"
        case .off: return "å…³é—­"
        }
    }
    
    var iconName: String {
        switch self {
        case .on: return "bolt.fill"
        case .off: return "bolt.slash.fill"
        }
    }
    
    var avFlashMode: AVCaptureDevice.FlashMode {
        switch self {
        case .on: return .on
        case .off: return .off
        }
    }
}

@MainActor
class CameraManager: NSObject, ObservableObject {
    private let preset: FilmPreset
    let session = AVCaptureSession()
    private var photoOutput = AVCapturePhotoOutput()
    private var videoCaptureDevice: AVCaptureDevice?
    private let videoDataOutput = AVCaptureVideoDataOutput()
    private let ciContext = CIContext(options: [CIContextOption.useSoftwareRenderer: false])
    private let previewQueue = DispatchQueue(label: "preview.lut.queue")
    fileprivate var latestPixelBuffer: CVPixelBuffer?
    // é¢„è§ˆæ–¹å‘ç¼“å­˜ï¼Œä¾›æ¸²æŸ“çº¿ç¨‹è¯»å–ï¼ˆé¿å…åœ¨æ¸²æŸ“çº¿ç¨‹ä¸­åš async æŸ¥è¯¢ï¼‰
    fileprivate var previewRotationAngle: CGFloat?
    fileprivate var previewDeviceOrientation: UIDeviceOrientation?
    // ç”¨äºç‚¹å‡»åæ ‡åˆ°ç›¸æœºåæ ‡çš„æ¢ç®—ï¼ˆä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
    private var conversionPreviewLayer: AVCaptureVideoPreviewLayer?
    private var photoDataHandler: ((Data?) -> Void)?
    @Published var flashMode: FlashMode = .off
    
    // 35mmç­‰æ•ˆç„¦è·ç›¸å…³å±æ€§
    private var devicePhysicalFocalLength: Float = 0.0 // è®¾å¤‡ç‰©ç†ç„¦è·
    private var device35mmEquivalentFocalLength: Float = 0.0 // è®¾å¤‡35mmç­‰æ•ˆç„¦è·
    @Published var targetFocalLength: Float = 35.0 // ç›®æ ‡35mmç­‰æ•ˆç„¦è·
    @Published var currentZoomFactor: CGFloat = 1.0 // å½“å‰å˜ç„¦ç³»æ•°
    private var requiredZoomFactor: CGFloat = 1.0 // è¾¾åˆ°35mmæ‰€éœ€çš„å˜ç„¦ç³»æ•°
    
    // ç„¦è·è°ƒæ•´èŒƒå›´
    private let minFocalLength: Float = 24.0 // æœ€å°35mmç­‰æ•ˆç„¦è·
    private let maxFocalLength: Float = 85.0 // æœ€å¤§35mmç­‰æ•ˆç„¦è·
    
    // ä½ç½®ç®¡ç†å™¨
    private let locationManager = CLLocationManager()
    private var currentLocation: CLLocation?
    // iOS 18 ä¼˜åŒ–ï¼šä½ç½®ç¼“å­˜ç­–ç•¥
    private var locationCache: [Date: CLLocation] = [:]
    private let locationCacheExpiry: TimeInterval = 30.0
    private var pendingLocationRequests: [UUID: CheckedContinuation<CLLocation?, Never>] = [:]

    @MainActor
    func currentLocationSnapshot() -> CLLocation? {
        return currentLocation
    }

    // iOS 18 ä¼˜åŒ–ï¼šè·å–ç¼“å­˜æˆ–æ–°é²œä½ç½®ï¼ˆæ— é˜»å¡ç­‰å¾…ï¼‰
    func cachedOrFreshLocation() async -> CLLocation? {
        let now = Date()

        // 1. æ£€æŸ¥30så†…çš„ç¼“å­˜
        if let recent = locationCache.values.first(where: {
            now.timeIntervalSince($0.timestamp) < locationCacheExpiry
        }) {
            return recent
        }

        // 2. ä½¿ç”¨å½“å‰ä½ç½®
        if let fresh = currentLocation {
            locationCache[now] = fresh
            // æ¸…ç†è¿‡æœŸç¼“å­˜
            locationCache = locationCache.filter { now.timeIntervalSince($0.value.timestamp) < locationCacheExpiry }
            return fresh
        }

        // 3. è§¦å‘åå°æ›´æ–°ï¼ˆä¸‹æ¬¡æ‹æ‘„ä½¿ç”¨ï¼‰
        locationManager.requestLocation()

        return nil
    }

    // ä¿ç•™åŸæ–¹æ³•ç”¨äºå…¼å®¹ï¼ˆå·²åºŸå¼ƒï¼Œå»ºè®®ä½¿ç”¨ cachedOrFreshLocationï¼‰
    @available(*, deprecated, message: "Use cachedOrFreshLocation() instead")
    func fetchFreshLocation(timeout: TimeInterval = 1.5, freshness: TimeInterval = 10.0) async -> CLLocation? {
        return await cachedOrFreshLocation()
    }
    
    // iOS 18 æ–¹å‘ç®¡ç†
    fileprivate var rotationCoordinator: AVCaptureDevice.RotationCoordinator?
    private var currentDeviceOrientation: UIDeviceOrientation = .portrait
    private var orientationObserver: NSObjectProtocol?
    private var subjectAreaObserver: NSObjectProtocol?

    // å›ºå®š ISO é…ç½®ï¼ˆéšèƒ¶ç‰‡é¢„è®¾ï¼‰
    @Published var isISOLocked: Bool = false
    private var fixedISOValue: Float
    private var lastISOAdjustTime: Date = .distantPast
    private let isoAdjustThrottle: TimeInterval = 2.0
    private var lastLogTime: Date = .distantPast
    private var lastAppliedISO: Float?
    private var lastAppliedExposureSeconds: Double?

    // è‡ªåŠ¨æµ‹å…‰å®šæ—¶å™¨ï¼ˆåœ¨å›ºå®š ISO å‰æä¸‹ï¼Œå‘¨æœŸæ€§åŸºäºæµ‹å…‰è°ƒæ•´å¿«é—¨ï¼‰
    private var exposureMeterTimer: Timer?
    // æ‹ç…§å‰çš„æ›å…‰è¡¥å¿è®°å½•ï¼ˆç”¨äºæ‹åæ¢å¤ï¼‰
    private var previousExposureTargetBias: Float = 0
    // æ ‡è®°æ˜¯å¦ä¸ºé—ªå…‰æ‹æ‘„çŸ­æš‚é”å®šäº†æ›å…‰
    private var lockedExposureForFlashCapture: Bool = false
    // ç‚¹å‡»å¯¹ç„¦ä¿æŒè®¡æ—¶
    private var focusHoldTimer: Timer?
    private let tapFocusHoldDuration: TimeInterval = 3.0
    
    init(preset: FilmPreset) {
        self.preset = preset
        self.fixedISOValue = 0
        super.init()
        setupCamera()
        setupOrientationMonitoring()
    }
    //ï¼ˆå·²å¼ƒç”¨ï¼‰ç‚¹å‡»å¯¹ç„¦åæ ‡æ¢ç®—
    
    deinit {
        if let observer = orientationObserver {
            NotificationCenter.default.removeObserver(observer)
        }
        if let subjectObserver = subjectAreaObserver {
            NotificationCenter.default.removeObserver(subjectObserver)
        }
    }
    
    // è®¾ç½®è®¾å¤‡æ–¹å‘ç›‘æ§
    private func setupOrientationMonitoring() {
        // å¯ç”¨è®¾å¤‡æ–¹å‘æ›´æ–°
        UIDevice.current.beginGeneratingDeviceOrientationNotifications()
        
        // ç›‘å¬æ–¹å‘å˜åŒ–
        orientationObserver = NotificationCenter.default.addObserver(
            forName: UIDevice.orientationDidChangeNotification,
            object: nil,
            queue: .main
        ) { [weak self] _ in
            Task { @MainActor in
                self?.updateDeviceOrientation()
            }
        }
        
        // åˆå§‹åŒ–å½“å‰æ–¹å‘
        updateDeviceOrientation()
        // è‹¥åˆå§‹è¯»å–åˆ°æ— æ•ˆæ–¹å‘ï¼ˆå¦‚æ¨ªå±è¿›å…¥æ—¶å¸¸è§çš„ .unknown/.faceUpï¼‰ï¼Œç”¨ç•Œé¢æ–¹å‘å›å¡«
        bootstrapInitialOrientationIfNeeded()
    }
    
    // æ›´æ–°è®¾å¤‡æ–¹å‘
    private func updateDeviceOrientation() {
        let orientation = UIDevice.current.orientation
        
        // åªå¤„ç†æœ‰æ•ˆçš„æ–¹å‘
        if orientation.isValidInterfaceOrientation {
            currentDeviceOrientation = orientation
            // åŒæ­¥ç¼“å­˜ï¼Œä¾›é¢„è§ˆæ¸²æŸ“åœ¨è§’åº¦ä¸å¯ç”¨æ—¶å›é€€ä½¿ç”¨
            self.previewDeviceOrientation = orientation
            print("ğŸ“± è®¾å¤‡æ–¹å‘æ›´æ–°: \(orientationDescription(orientation))")
            applyVideoOrientationToOutputs()
        }
    }
    
    // æ–¹å‘æè¿°
    private func orientationDescription(_ orientation: UIDeviceOrientation) -> String {
        switch orientation {
        case .portrait: return "Portrait"
        case .portraitUpsideDown: return "Portrait Upside Down"
        case .landscapeLeft: return "Landscape Left"
        case .landscapeRight: return "Landscape Right"
        default: return "Unknown"
        }
    }

    // å½“ UIDeviceOrientation åˆå§‹æ— æ•ˆæ—¶ï¼Œä»çª—å£åœºæ™¯çš„ç•Œé¢æ–¹å‘æ¨æ–­ä¸€æ¬¡ï¼Œä¿®æ­£æ¨ªå±è¿›å…¥çš„åˆå§‹çŠ¶æ€
    private func bootstrapInitialOrientationIfNeeded() {
        // ä»…å½“å°šæœªç¼“å­˜æœ‰æ•ˆçš„é¢„è§ˆæ–¹å‘æ—¶å›å¡«
        if previewDeviceOrientation == nil || previewDeviceOrientation == .unknown {
            if let scene = UIApplication.shared.connectedScenes.first as? UIWindowScene {
                let io = scene.interfaceOrientation
                let dev: UIDeviceOrientation
                switch io {
                case .portrait: dev = .portrait
                case .portraitUpsideDown: dev = .portraitUpsideDown
                case .landscapeLeft: dev = .landscapeRight // çª—å£æ–¹å‘ä¸è®¾å¤‡æ–¹å‘åœ¨æ¨ªå±ä¸Šç›¸å
                case .landscapeRight: dev = .landscapeLeft
                default: dev = .portrait
                }
                self.previewDeviceOrientation = dev
                self.currentDeviceOrientation = dev
                applyVideoOrientationToOutputs()
            }
        }
    }
    
    // å…¼å®¹æ—§ç‰ˆæœ¬ï¼šä»…ç¼“å­˜è®¾å¤‡æ–¹å‘ï¼Œç”±æ¸²æŸ“ä¸EXIFå†™å…¥å¤„ç†æ–¹å‘
    // ä¸å†ä½¿ç”¨å·²åºŸå¼ƒçš„ AVCaptureConnection.videoOrientation

    // iOS 18: åŒæ­¥å½“å‰æ–¹å‘åˆ°é¢„è§ˆ/æ‹ç…§è¾“å‡ºè¿æ¥
    private func applyVideoOrientationToOutputs() {
        guard let coordinator = rotationCoordinator else { return }

        let angle = coordinator.videoRotationAngleForHorizonLevelCapture

        // è®¾ç½®æ‹ç…§è¾“å‡ºè§’åº¦
        if let pconn = photoOutput.connection(with: .video),
           pconn.isVideoRotationAngleSupported(angle) {
            pconn.videoRotationAngle = angle
        }

        if let lconn = conversionPreviewLayer?.connection,
           lconn.isVideoRotationAngleSupported(angle) {
            lconn.videoRotationAngle = angle
        }

        // ç¼“å­˜ç»™æ¸²æŸ“çº¿ç¨‹ä½¿ç”¨
        self.previewRotationAngle = angle
    }

    // å·²æ”¹ä¸ºå…¨è‡ªåŠ¨å¯¹ç„¦
    @MainActor
    func setFocusAndExposure(normalizedPoint: CGPoint) {}

    // æŒ‰è·ç¦»ä¼°ç®—æ‰‹ç”µç­’äº®åº¦ï¼Œå¹¶å¼€å¯ï¼›è¿”å›æ˜¯å¦å¯ç”¨
    @MainActor
    func enableAutoTorchForCapture() -> Bool {
        guard let device = videoCaptureDevice, device.hasTorch else { return false }
        // ä»…æ ¹æ®è¢«æ‘„ç‰©ä½“è¿œè¿‘ï¼ˆé•œå¤´ä½ç½®ï¼‰æ§åˆ¶å¼ºåº¦ï¼š
        // æœŸæœ›åŒºé—´ï¼ˆå»ºè®®ï¼‰ï¼š>3mâ‰ˆå…¨å¼€(1.0)ï¼Œ2~3mâ‰ˆ0.8ï¼Œ1~2mâ‰ˆ0.6ï¼Œ<1mâ‰ˆ0.4
        // è¯´æ˜ï¼šlensPosition ä¸ºå¯¹ç„¦ä½ç½®çš„è¿‘ä¼¼ï¼Œ0â‰ˆè¿‘ã€1â‰ˆè¿œï¼Œä¸åŒæœºå‹éçº¿æ€§ï¼›é˜ˆå€¼ä¸ºç»éªŒå€¼ï¼Œå¯åç»­è°ƒä¼˜
        let lensPos = max(0.0, min(1.0, CGFloat(device.lensPosition)))
        // ç»éªŒé˜ˆå€¼ï¼ˆå¯æŒ‰æœºå‹å¾®è°ƒï¼‰
        let near1: CGFloat = 0.20  // ~1m å†…
        let near2: CGFloat = 0.45  // ~1-2m
        let near3: CGFloat = 0.70  // ~2-3m
        let level: CGFloat
        if lensPos <= near1 {
            level = 0.40
        } else if lensPos <= near2 {
            level = 0.60
        } else if lensPos <= near3 {
            level = 0.80
        } else {
            level = 1.00
        }
        print("ğŸ”¦ Torch: lensPos=\(String(format: "%.3f", lensPos)) â†’ level=\(String(format: "%.2f", level)))")
        do {
            try device.lockForConfiguration()
            try device.setTorchModeOn(level: Float(level))
            device.unlockForConfiguration()
            return true
        } catch {
            print("âš ï¸ å¼€å¯æ‰‹ç”µç­’å¤±è´¥: \(error)")
            return false
        }
    }
    
    // iOS 18: ä»æ—‹è½¬è§’åº¦è½¬æ¢ä¸ºEXIFæ–¹å‘å€¼
    private func exifOrientationFromRotationAngle(_ rotationAngle: CGFloat) -> Int {
        let normalizedAngle = Int(rotationAngle) % 360
        switch normalizedAngle {
        case 0:
            return 1    // æ­£å¸¸æ–¹å‘ 0Â°
        case 90, -270:
            return 6    // é€†æ—¶é’ˆæ—‹è½¬90åº¦
        case 180, -180:
            return 3    // æ—‹è½¬180åº¦
        case 270, -90:
            return 8    // é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
        default:
            return 1    // é»˜è®¤ä¸ºæ­£å¸¸æ–¹å‘
        }
    }

    // iOS 18: ä»æ—‹è½¬è§’åº¦è½¬æ¢ä¸ºCIImageæ–¹å‘
    fileprivate func orientationFromRotationAngle(_ rotationAngle: CGFloat) -> CGImagePropertyOrientation {
        let normalizedAngle = Int(rotationAngle) % 360
        switch normalizedAngle {
        case 0:
            return .up          // æ­£å¸¸æ–¹å‘ 0Â°
        case 90, -270:
            return .right       // é€†æ—¶é’ˆæ—‹è½¬90åº¦
        case 180, -180:
            return .down        // æ—‹è½¬180åº¦
        case 270, -90:
            return .left        // é¡ºæ—¶é’ˆæ—‹è½¬90åº¦
        default:
            return .up          // é»˜è®¤ä¸ºæ­£å¸¸æ–¹å‘
        }
    }
    
    func requestCameraPermission() {
        Task {
        let status = AVCaptureDevice.authorizationStatus(for: .video)
        
        switch status {
        case .authorized:
                await startSession()
                startLocationServices() // ä»…åœ¨ç›¸æœºå¯åŠ¨æ—¶å¼€å¯GPS
        case .notDetermined:
                let granted = await AVCaptureDevice.requestAccess(for: .video)
                    if granted {
                    await startSession()
                    startLocationServices() // ä»…åœ¨ç›¸æœºå¯åŠ¨æ—¶å¼€å¯GPS
                }
            default:
                break
            }
        }
    }
    
    private func setupCamera() {
        // iOS 18 ä¼˜åŒ–ï¼šæ‰¹é‡é…ç½®ä»¥å‡å°‘å¼€é”€
        session.beginConfiguration()
        defer { session.commitConfiguration() }

        session.sessionPreset = .photo

        guard let videoCaptureDevice = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            print("âŒ Failed to get camera device")
            return
        }

        self.videoCaptureDevice = videoCaptureDevice

        // è¯»å–è®¾å¤‡ç„¦è·ä¿¡æ¯
        readCameraSpecs(device: videoCaptureDevice)

        // å›ºå®š 35mm ç­‰æ•ˆç„¦è·
        calculateZoomFactorFor35mm()

        do {
            let videoInput = try AVCaptureDeviceInput(device: videoCaptureDevice)

            if session.canAddInput(videoInput) {
                session.addInput(videoInput)
            }

            if session.canAddOutput(photoOutput) {
                session.addOutput(photoOutput)

                // iOS 18 ä¼˜åŒ–ï¼šå“åº”å¼æ‹æ‘„ + å¿«é€Ÿè¿æ‹
                photoOutput.maxPhotoQualityPrioritization = .speed
                photoOutput.isResponsiveCaptureEnabled = true
                photoOutput.isFastCapturePrioritizationEnabled = true

                // ç²¾ç¡®æ§åˆ¶è¾“å‡ºå°ºå¯¸ï¼ˆä»æ”¯æŒçš„å°ºå¯¸ä¸­é€‰æ‹©ï¼‰
                let format = videoCaptureDevice.activeFormat
                let supportedDimensions = format.supportedMaxPhotoDimensions

                // é€‰æ‹©æœ€æ¥è¿‘ 4:3 æ¯”ä¾‹ä¸”ä¸è¶…è¿‡ 4000px å®½åº¦çš„å°ºå¯¸
                let preferred = supportedDimensions.filter { dim in
                    let ratio = Float(dim.width) / Float(dim.height)
                    return dim.width <= 4000 && abs(ratio - 4.0/3.0) < 0.1
                }.max { $0.width < $1.width }

                if let selected = preferred {
                    photoOutput.maxPhotoDimensions = selected
                    print("ğŸ“ Photo dimensions: \(selected.width)Ã—\(selected.height)")
                } else if let largest = supportedDimensions.max(by: { $0.width < $1.width }) {
                    // å›é€€ï¼šä½¿ç”¨æœ€å¤§æ”¯æŒå°ºå¯¸
                    photoOutput.maxPhotoDimensions = largest
                    print("ğŸ“ Photo dimensions (fallback): \(largest.width)Ã—\(largest.height)")
                }

                // Rotation coordinator
                rotationCoordinator = AVCaptureDevice.RotationCoordinator(
                    device: videoCaptureDevice,
                    previewLayer: nil
                )
                print("ğŸ“± Using iOS 18 AVCaptureDevice.RotationCoordinator")
            }

            // å®æ—¶é¢„è§ˆæ•°æ®è¾“å‡ºï¼ˆä¾› CI ç®¡çº¿ä½¿ç”¨ï¼‰
            videoDataOutput.alwaysDiscardsLateVideoFrames = true
            videoDataOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA]
            if session.canAddOutput(videoDataOutput) {
                session.addOutput(videoDataOutput)
                videoDataOutput.setSampleBufferDelegate(self, queue: previewQueue)
                applyVideoOrientationToOutputs()
            }

            // å…¨è‡ªåŠ¨å¯¹ç„¦/æ›å…‰é»˜è®¤é…ç½®
            try videoCaptureDevice.lockForConfiguration()
            if videoCaptureDevice.isFocusModeSupported(.continuousAutoFocus) {
                videoCaptureDevice.focusMode = .continuousAutoFocus
            }
            if videoCaptureDevice.isExposureModeSupported(.continuousAutoExposure) {
                videoCaptureDevice.exposureMode = .continuousAutoExposure
            }
            if videoCaptureDevice.isSmoothAutoFocusSupported {
                videoCaptureDevice.isSmoothAutoFocusEnabled = true
            }
            videoCaptureDevice.unlockForConfiguration()

            // å¯ç”¨ä¸»ä½“åŒºåŸŸå˜åŒ–ç›‘æ§ï¼ˆè‡ªåŠ¨å¯¹ç„¦æ—¶æ›´çµæ•ï¼‰
            try videoCaptureDevice.lockForConfiguration()
            if videoCaptureDevice.isSubjectAreaChangeMonitoringEnabled == false {
                videoCaptureDevice.isSubjectAreaChangeMonitoringEnabled = true
            }
            // åˆå§‹ä½¿ç”¨è¿ç»­è‡ªåŠ¨æ›å…‰ä»¥ä¾¿æµ‹å…‰
            if videoCaptureDevice.isExposureModeSupported(.continuousAutoExposure) {
                videoCaptureDevice.exposureMode = .continuousAutoExposure
            }
            videoCaptureDevice.unlockForConfiguration()
            
            subjectAreaObserver = NotificationCenter.default.addObserver(
                forName: AVCaptureDevice.subjectAreaDidChangeNotification,
                object: videoCaptureDevice,
                queue: .main
            ) { _ in }
        } catch {
            print("Error setting up camera: \(error)")
        }
    }
    
    private func startSession() async {
        guard !session.isRunning else { return }
        
        // åœ¨åå°çº¿ç¨‹å¯åŠ¨ç›¸æœºä¼šè¯ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
        await Task.detached { [weak self] in
            await self?.session.startRunning()
        }.value
        // ä¼šè¯å¯åŠ¨åå†æ¬¡åº”ç”¨ 35mm ç­‰æ•ˆå˜ç„¦ï¼Œç¡®ä¿ç”Ÿæ•ˆ
        await MainActor.run {
            self.calculateZoomFactorFor35mm()
            self.applyVideoOrientationToOutputs()
        }
    }
    
    @MainActor
    func capturePhoto(completion: @escaping (Data?) -> Void) {
        photoDataHandler = completion

        let settings = AVCapturePhotoSettings()

        // iOS 18 ä¼˜åŒ–ï¼šå¿«é€Ÿæ‹æ‘„ä¼˜å…ˆçº§
        settings.photoQualityPrioritization = .speed
        
        // é—ªå…‰ç¯/æ‰‹ç”µç­’ç­–ç•¥ï¼šè‹¥å¼€å¯ï¼ŒæŒ‰è·ç¦»(å¯¹ç„¦ä½ç½®)ä¼°ç®—æ‰‹ç”µç­’å¼ºåº¦ï¼Œä½¿ç”¨æŒç»­å…‰ä»£æ›¿ä¸€æ¬¡æ€§é—ªå…‰
        // ä½¿ç”¨çœŸå®é—ªå…‰ç¯ï¼ˆä¸å†ç”¨æ‰‹ç”µç­’æ¨¡æ‹Ÿï¼‰ï¼Œå¹¶åœ¨æ‹ç…§å‰æŒ‰è·ç¦»è®¾ç½®æ›å…‰è¡¥å¿ä»¥é—´æ¥æ§åˆ¶é—ªå…‰æ•ˆæœ
        if let device = videoCaptureDevice, device.hasFlash {
            settings.flashMode = (flashMode == .on) ? .on : .off
            if flashMode == .on {
                // ä¾æ®å¯¹ç„¦è¿œè¿‘è®¾ç½®æ›å…‰åç½®ï¼ˆ6æ®µæ›´å¼ºçƒˆï¼‰ï¼Œå¹¶çŸ­æš‚é”æ›å…‰åå†æ‹
                // lensPosition: 0â‰ˆè¿‘, 1â‰ˆè¿œï¼›é˜ˆå€¼ä¸åç½®ä¸ºç»éªŒå€¼ï¼Œå¯åç»­æœºå‹è°ƒä¼˜
                let lensPos = max(0.0, min(1.0, device.lensPosition))
                let bias: Float
                if lensPos < 0.10 {           // è¿‘åˆ°æè¿‘
                    bias = -0.8
                } else if lensPos < 0.25 {    // è¿‘
                    bias = -0.4
                } else if lensPos < 0.50 {    // ä¸­è¿‘
                    bias = -0.1
                } else if lensPos < 0.75 {    // ä¸­è¿œ
                    bias = 0.2
                } else if lensPos < 0.85 {    // è¿œ
                    bias = 0.5
                } else {                       // æè¿œ
                    bias = 0.7
                }
                do {
                    try device.lockForConfiguration()
                    previousExposureTargetBias = device.exposureTargetBias
                    let clamped = clamp(bias, min: device.minExposureTargetBias, max: device.maxExposureTargetBias)
                    device.setExposureTargetBias(clamped) { _ in }
                    // çŸ­æš‚é”å®šæ›å…‰ï¼Œé¿å… AE ç«‹åˆ»æŠµæ¶ˆåç½®
                    if device.isExposureModeSupported(.locked) {
                        device.exposureMode = .locked
                        lockedExposureForFlashCapture = true
                    }
                    device.unlockForConfiguration()
                    print(String(format: "âš¡ï¸ Flash PreBias: lensPos=%.3f â†’ bias=%.2f (range %.1f..%.1f)", lensPos, bias, device.minExposureTargetBias, device.maxExposureTargetBias))
                } catch {
                    print("âš ï¸ è®¾ç½®æ›å…‰åç½®å¤±è´¥: \(error)")
                }
            }
        }
        
        // å¯ç”¨å®Œæ•´çš„å…ƒæ•°æ®ä¿ç•™
        settings.embedsDepthDataInPhoto = false
        settings.embedsPortraitEffectsMatteInPhoto = false
        settings.embedsSemanticSegmentationMattesInPhoto = false
        
        // iOS 18 ä¼˜åŒ–ï¼šä½¿ç”¨ RotationCoordinator è®¾ç½®ç…§ç‰‡æ–¹å‘
        if let coordinator = rotationCoordinator,
           let connection = photoOutput.connection(with: .video) {
            let rotationAngle = coordinator.videoRotationAngleForHorizonLevelCapture
            if connection.isVideoRotationAngleSupported(rotationAngle) {
                connection.videoRotationAngle = rotationAngle
            }
        }
        
        // æ·»åŠ ä½ç½®ä¿¡æ¯åˆ°ç…§ç‰‡è®¾ç½®ä¸­
        if let location = currentLocation {
            print("ğŸ“ æ·»åŠ GPSä½ç½®ä¿¡æ¯: \(location.coordinate)")
        }
        
        // è‹¥è¿›è¡Œäº†æ›å…‰é”å®šï¼Œå»¶è¿ŸçŸ­æš‚æ—¶é—´å†è§¦å‘æ‹ç…§
        if lockedExposureForFlashCapture {
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.20) {
                self.photoOutput.capturePhoto(with: settings, delegate: self)
            }
        } else {
            photoOutput.capturePhoto(with: settings, delegate: self)
        }

        // æ‹å®Œåœ¨ä»£ç†å›è°ƒé‡Œå…³é—­æ‰‹ç”µç­’ï¼ˆè§ä¸‹ï¼‰
    }
    
    func toggleFlashMode() {
        let modes = FlashMode.allCases
        if let currentIndex = modes.firstIndex(of: flashMode) {
            let nextIndex = (currentIndex + 1) % modes.count
            flashMode = modes[nextIndex]
        }
    }
    
    // MARK: - 35mmç­‰æ•ˆç„¦è·ç›¸å…³æ–¹æ³•
    
    // è¯»å–ç›¸æœºè§„æ ¼ä¿¡æ¯
    private func readCameraSpecs(device: AVCaptureDevice) {
        // è·å–è®¾å¤‡çš„ç‰©ç†ç„¦è·ï¼ˆé€šå¸¸åœ¨é•œå¤´ä¿¡æ¯ä¸­ï¼‰
        let lensPosition = device.lensPosition
        print("ğŸ“· é•œå¤´ä½ç½®: \(lensPosition)")
        
        // è·å–è®¾å¤‡çš„35mmç­‰æ•ˆç„¦è·ä¿¡æ¯
        // iPhoneçš„ä¸»æ‘„é€šå¸¸æœ‰å›ºå®šçš„35mmç­‰æ•ˆç„¦è·å€¼
        let deviceModel = getModelIdentifier()
        let systemVersion = UIDevice.current.systemVersion
        
        print("ğŸ“± è®¾å¤‡å‹å·: \(deviceModel)")
        print("ğŸ“± ç³»ç»Ÿç‰ˆæœ¬: \(systemVersion)")
        
        // æ ¹æ®è®¾å¤‡å‹å·æ¨æ–­35mmç­‰æ•ˆç„¦è·
        // è¿™äº›å€¼åŸºäºè‹¹æœå®˜æ–¹è§„æ ¼
        device35mmEquivalentFocalLength = estimate35mmEquivalentFocalLength()
        devicePhysicalFocalLength = estimatePhysicalFocalLength()
        
        print("ğŸ“ è®¾å¤‡ç‰©ç†ç„¦è·: \(devicePhysicalFocalLength)mm")
        print("ğŸ“ è®¾å¤‡35mmç­‰æ•ˆç„¦è·: \(device35mmEquivalentFocalLength)mm")
        print("ğŸ¯ ç›®æ ‡35mmç­‰æ•ˆç„¦è·: \(targetFocalLength)mm")
    }
    
    // ä¼°ç®—è®¾å¤‡çš„35mmç­‰æ•ˆç„¦è·
    private func estimate35mmEquivalentFocalLength() -> Float {
        let modelName = getModelIdentifier()
        print("ğŸ“± è®¾å¤‡æ ‡è¯†ç¬¦/åç§°: \(modelName)")

        // åŸºäºæœºå‹çš„ä¸»æ‘„ç­‰æ•ˆç„¦è·è¿‘ä¼¼ï¼ˆä¸è¶³ä»¥ä¸¥è°¨ï¼Œä½†è¶³å¤Ÿç”¨äºè®¾å®šç›®æ ‡è§†è§’ï¼‰
        // 16 Pro ç³»åˆ—ä¸»æ‘„ 24mmï¼›16 é Pro ä¸º 26mm
        // 15 Pro ç³»åˆ—ä¸»æ‘„ 24mmï¼›å¤§å¤šæ•° 12/13/14/15 é Pro ä¸º 26mmï¼›æ›´è€è®¾å¤‡å¤šä¸º 28mm
        let name = modelName
        if name.contains("16 Pro") { return 24.0 }
        if name.contains("16") { return 26.0 }
        if name.contains("15 Pro") { return 24.0 }
        if name.contains("15") { return 26.0 }
        if name.contains("14") || name.contains("13") || name.contains("12") || name.contains("11") || name.contains("XS") || name.contains("XR") || name.contains(" iPhone X") { return 26.0 }
        if name.contains("8") || name.contains("7") || name.contains("6") { return 28.0 }
        // æ¨¡æ‹Ÿå™¨æˆ–æœªçŸ¥æœºå‹
        return 26.0
    }
    
    // è·å–ç²¾ç¡®çš„è®¾å¤‡å‹å·æ ‡è¯†ç¬¦
    private func getModelIdentifier() -> String {
        var systemInfo = utsname()
        uname(&systemInfo)
        let machineMirror = Mirror(reflecting: systemInfo.machine)
        let identifier = machineMirror.children.reduce("") { identifier, element in
            guard let value = element.value as? Int8, value != 0 else { return identifier }
            return identifier + String(Character(UnicodeScalar(UInt8(value))))
        }
        
        // ä½¿ç”¨ç®€åŒ–æ–¹å¼æ£€æµ‹æ¨¡æ‹Ÿå™¨
        #if targetEnvironment(simulator)
        return "iPhone 15 Pro (Simulator)"
        #else
        return deviceModelName(from: identifier)
        #endif
    }
    
    // å°†è®¾å¤‡æ ‡è¯†ç¬¦è½¬æ¢ä¸ºå¯è¯»çš„è®¾å¤‡åç§°
    private func deviceModelName(from identifier: String) -> String {
        switch identifier {
        // iPhone 16 ç³»åˆ—ï¼ˆæ¨æµ‹çš„æ ‡è¯†ç¬¦ï¼‰
        case "iPhone17,1": return "iPhone 16"
        case "iPhone17,2": return "iPhone 16 Plus"
        case "iPhone17,3": return "iPhone 16 Pro"
        case "iPhone17,4": return "iPhone 16 Pro Max"
        
        // iPhone 15 ç³»åˆ—
        case "iPhone16,1": return "iPhone 15"
        case "iPhone16,2": return "iPhone 15 Plus"
        case "iPhone16,3": return "iPhone 15 Pro"
        case "iPhone16,4": return "iPhone 15 Pro Max"
            
        // iPhone 14 ç³»åˆ—
        case "iPhone15,4": return "iPhone 14"
        case "iPhone15,5": return "iPhone 14 Plus"
        case "iPhone15,2": return "iPhone 14 Pro"
        case "iPhone15,3": return "iPhone 14 Pro Max"
            
        // iPhone 13 ç³»åˆ—
        case "iPhone14,4": return "iPhone 13 mini"
        case "iPhone14,5": return "iPhone 13"
        case "iPhone14,6": return "iPhone 13 Pro"
        case "iPhone14,2": return "iPhone 13 Pro"
        case "iPhone14,3": return "iPhone 13 Pro Max"
            
        // iPhone 12 ç³»åˆ—
        case "iPhone13,1": return "iPhone 12 mini"
        case "iPhone13,2": return "iPhone 12"
        case "iPhone13,3": return "iPhone 12 Pro"
        case "iPhone13,4": return "iPhone 12 Pro Max"
            
        // iPhone 11 ç³»åˆ—
        case "iPhone12,1": return "iPhone 11"
        case "iPhone12,3": return "iPhone 11 Pro"
        case "iPhone12,5": return "iPhone 11 Pro Max"
            
        // iPhone X ç³»åˆ—
        case "iPhone11,2": return "iPhone XS"
        case "iPhone11,4", "iPhone11,6": return "iPhone XS Max"
        case "iPhone11,8": return "iPhone XR"
        case "iPhone10,3", "iPhone10,6": return "iPhone X"
            
        // è¾ƒè€çš„iPhoneå‹å·
        case "iPhone10,1", "iPhone10,4": return "iPhone 8"
        case "iPhone10,2", "iPhone10,5": return "iPhone 8 Plus"
        case "iPhone9,1", "iPhone9,3": return "iPhone 7"
        case "iPhone9,2", "iPhone9,4": return "iPhone 7 Plus"
        case "iPhone8,1": return "iPhone 6s"
        case "iPhone8,2": return "iPhone 6s Plus"
        case "iPhone7,2": return "iPhone 6"
        case "iPhone7,1": return "iPhone 6 Plus"
            
        default:
            // å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…·ä½“å‹å·ï¼Œè¿”å›é€šç”¨åç§°
            return "iPhone (\(identifier))"
        }
    }
    
    // ä¼°ç®—è®¾å¤‡çš„ç‰©ç†ç„¦è·
    private func estimatePhysicalFocalLength() -> Float {
        // iPhoneçš„ç‰©ç†ç„¦è·é€šå¸¸åœ¨5-7mmä¹‹é—´
        // è¿™ä¸ªå€¼ä¸»è¦ç”¨äºè®¡ç®—ï¼Œå®é™…ç„¦è·ä¿¡æ¯è¾ƒéš¾ç›´æ¥è·å–
        return 6.0 // å…¸å‹çš„iPhoneä¸»æ‘„ç‰©ç†ç„¦è·
    }
    
    // è®¡ç®—è¾¾åˆ°35mmç­‰æ•ˆç„¦è·æ‰€éœ€çš„å˜ç„¦ç³»æ•°
    private func calculateZoomFactorFor35mm() {
        guard let device = videoCaptureDevice else { return }
        // å°½å¯èƒ½ç”¨è®¾å¤‡æä¾›çš„ 35mm ç­‰æ•ˆä¿¡æ¯ï¼Œå›é€€ 26mm
        let baseEquivalent: Float = device35mmEquivalentFocalLength > 0 ? device35mmEquivalentFocalLength : 26.0
        requiredZoomFactor = CGFloat(targetFocalLength / baseEquivalent)

        let maxZoom = device.activeFormat.videoMaxZoomFactor
        let minZoom = device.minAvailableVideoZoomFactor
        requiredZoomFactor = max(minZoom, min(maxZoom, requiredZoomFactor))

        applyZoomFactor(requiredZoomFactor)
    }
    
    // åº”ç”¨å˜ç„¦ç³»æ•°
    private func applyZoomFactor(_ zoomFactor: CGFloat) {
        guard let device = videoCaptureDevice else { return }
        
        do {
            try device.lockForConfiguration()
            device.videoZoomFactor = zoomFactor
            currentZoomFactor = zoomFactor
            device.unlockForConfiguration()
            
            print("âœ… å›ºå®š35mmç­‰æ•ˆç„¦è·ï¼Œå˜ç„¦ç³»æ•°: \(String(format: "%.2f", zoomFactor))x")
        } catch {
            print("âŒ åº”ç”¨å˜ç„¦å¤±è´¥: \(error)")
        }
    }

    // MARK: - å›ºå®š ISO 400 é€»è¾‘
    private func scheduleReapplyFixedISO(initial: Bool = false) { }

    private func clamp<T: Comparable>(_ value: T, min minValue: T, max maxValue: T) -> T {
        return max(minValue, min(maxValue, value))
    }

    private func cmTime(fromSeconds seconds: Double) -> CMTime {
        return CMTimeMakeWithSeconds(seconds, preferredTimescale: 1_000_000_000)
    }

    private func exposureSeconds(_ time: CMTime) -> Double {
        guard time.timescale != 0 else { return 0 }
        return Double(time.value) / Double(time.timescale)
    }

    private func applyFixedISOAfterAutoMetering() async { }

    // å¯¹å¤–æš´éœ²ä¸€æ¬¡æ€§å¼ºåˆ¶åº”ç”¨å›ºå®š ISOï¼ˆæ‹ç…§å‰è°ƒç”¨ï¼‰
    func forceApplyFixedISO() async { }
    
    // è°ƒæ•´ç›®æ ‡ç„¦è·
    func adjustTargetFocalLength(_ newFocalLength: Float) {
        // é™åˆ¶ç„¦è·èŒƒå›´
        let clampedFocalLength = max(minFocalLength, min(maxFocalLength, newFocalLength))
        targetFocalLength = clampedFocalLength
        
        // é‡æ–°è®¡ç®—å¹¶åº”ç”¨å˜ç„¦ç³»æ•°
        calculateZoomFactorFor35mm()
        
        print("ğŸ¯ è°ƒæ•´ç›®æ ‡ç„¦è·ä¸º: \(String(format: "%.0f", targetFocalLength))mm")
    }
    
    // å¯åŠ¨ä½ç½®æœåŠ¡ï¼ˆä»…åœ¨æ‹æ‘„é¡µé¢ï¼‰
    private func startLocationServices() {
        print("ğŸ“ å¯åŠ¨GPSä½ç½®æœåŠ¡ï¼ˆæ‹æ‘„æ¨¡å¼ï¼‰")
        
        // é…ç½®ä½ç½®ç®¡ç†å™¨
        locationManager.delegate = self
        locationManager.desiredAccuracy = kCLLocationAccuracyBest
        locationManager.distanceFilter = 5
        
        // è¯·æ±‚æˆæƒï¼›è‹¥å·²æˆæƒï¼Œç«‹å³å¯åŠ¨æ›´æ–°ä¸ä¸€æ¬¡æ€§è¯·æ±‚
        locationManager.requestWhenInUseAuthorization()
        if #available(iOS 14.0, *) {
            let status = locationManager.authorizationStatus
            print("ğŸ“ å½“å‰å®šä½æˆæƒçŠ¶æ€: \(authorizationStatusDescription(status))")
            switch status {
            case .authorizedAlways, .authorizedWhenInUse:
                startLocationUpdates()
                Task { @MainActor in self.locationManager.requestLocation() }
            case .notDetermined, .denied, .restricted:
                break
            @unknown default:
                break
            }
        } else {
            let status = CLLocationManager.authorizationStatus()
            print("ğŸ“ å½“å‰å®šä½æˆæƒçŠ¶æ€(legacy): \(authorizationStatusDescription(status))")
            switch status {
            case .authorizedAlways, .authorizedWhenInUse:
                startLocationUpdates()
                Task { @MainActor in self.locationManager.requestLocation() }
            case .notDetermined, .denied, .restricted:
                break
            @unknown default:
                break
            }
        }
    }
    
    // æƒé™çŠ¶æ€æè¿°
    private func authorizationStatusDescription(_ status: CLAuthorizationStatus) -> String {
        switch status {
        case .notDetermined:
            return "æœªç¡®å®š"
        case .denied:
            return "å·²æ‹’ç»"
        case .restricted:
            return "å—é™åˆ¶"
        case .authorizedWhenInUse:
            return "ä½¿ç”¨æ—¶æˆæƒ"
        case .authorizedAlways:
            return "å§‹ç»ˆæˆæƒ"
        @unknown default:
            return "æœªçŸ¥çŠ¶æ€"
        }
    }
    
    // å®é™…å¯åŠ¨ä½ç½®æ›´æ–°
    private func startLocationUpdates() {
        // åœ¨åå°æ£€æŸ¥ä½ç½®æœåŠ¡çŠ¶æ€ï¼Œé¿å…ä¸»çº¿ç¨‹é˜»å¡
        Task.detached { [weak self] in
            guard let self = self else { return }
            
            let locationServicesEnabled = CLLocationManager.locationServicesEnabled()
            
            await MainActor.run {
                guard locationServicesEnabled else {
                    print("ğŸ“ ç³»ç»Ÿä½ç½®æœåŠ¡æœªå¯ç”¨ï¼Œæ— æ³•è·å–ä½ç½®")
                    return
                }
                
                print("ğŸ“ å¼€å§‹ä½ç½®æ›´æ–°")
                self.locationManager.startUpdatingLocation()
                self.locationManager.startUpdatingHeading()
                self.startLocationTimer()
            }
        }
    }
    
    // åœæ­¢ä½ç½®æœåŠ¡
    func stopLocationServices() {
        print("ğŸ“ åœæ­¢GPSä½ç½®æœåŠ¡")
        locationManager.stopUpdatingLocation()
        locationTimer?.invalidate()
        locationTimer = nil
        stopExposureMeteringTimer()
    }
    
    // ä½ç½®æ›´æ–°å®šæ—¶å™¨
    private var locationTimer: Timer?
    
    private func startLocationTimer() {
        locationTimer?.invalidate()
        locationTimer = Timer.scheduledTimer(withTimeInterval: 30.0, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            
            // æ¯30ç§’é‡æ–°è·å–ä¸€æ¬¡ä½ç½®
            Task { @MainActor in
                if CLLocationManager.locationServicesEnabled() {
                    print("ğŸ“ 30ç§’å®šæ—¶æ›´æ–°GPSä½ç½®")
                    self.locationManager.requestLocation() // å•æ¬¡ä½ç½®è¯·æ±‚
                }
            }
        }
    }

    // MARK: - è‡ªåŠ¨æµ‹å…‰ï¼ˆå›ºå®šISOå‰æä¸‹ï¼‰
    private func startExposureMeteringTimer() {
        // ä¸ºé¿å…é¢‘é—ªï¼Œä¸å†é«˜é¢‘æ‰“æ–­é¢„è§ˆå»é‡è®¾æ›å…‰
        exposureMeterTimer?.invalidate()
        exposureMeterTimer = Timer.scheduledTimer(withTimeInterval: 3.0, repeats: true) { [weak self] _ in
            guard let self = self else { return }
            Task { @MainActor in
                self.scheduleReapplyFixedISO()
            }
        }
    }

    private func stopExposureMeteringTimer() {
        exposureMeterTimer?.invalidate()
        exposureMeterTimer = nil
    }
}

// MARK: - CLLocationManagerDelegate
extension CameraManager: CLLocationManagerDelegate {
    nonisolated func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {
        Task { @MainActor in
            if let location = locations.last {
                self.currentLocation = location
                let age = Date().timeIntervalSince(location.timestamp)
                print(String(format: "ğŸ“ ä½ç½®æ›´æ–° lat=%.6f lon=%.6f alt=%.1f acc=%.1f age=%.2fs",
                              location.coordinate.latitude, location.coordinate.longitude,
                              location.altitude, location.horizontalAccuracy, age))
                // å”¤é†’ç­‰å¾…ä¸­çš„è¯·æ±‚
                if !self.pendingLocationRequests.isEmpty {
                    for (id, cont) in self.pendingLocationRequests { cont.resume(returning: location); self.pendingLocationRequests.removeValue(forKey: id) }
                }
            }
        }
    }
    
    nonisolated func locationManager(_ manager: CLLocationManager, didFailWithError error: Error) {
        print("ğŸ“ ä½ç½®è·å–å¤±è´¥: \(error.localizedDescription)")
    }
    
    nonisolated func locationManager(_ manager: CLLocationManager, didChangeAuthorization status: CLAuthorizationStatus) {
        Task { @MainActor in
            print("ğŸ“ ä½ç½®æƒé™çŠ¶æ€å˜åŒ–: \(self.authorizationStatusDescription(status))")
            
            switch status {
            case .authorizedWhenInUse, .authorizedAlways:
                print("ğŸ“ ä½ç½®æƒé™è·å¾—ï¼Œå¼€å§‹ä½ç½®æ›´æ–°")
                self.startLocationUpdates()
            case .denied, .restricted:
                print("ğŸ“ ä½ç½®æƒé™è¢«æ‹’ç»æˆ–å—é™ï¼Œåœæ­¢ä½ç½®æœåŠ¡")
                self.stopLocationServices()
            case .notDetermined:
                print("ğŸ“ ä½ç½®æƒé™ä»æœªç¡®å®šï¼Œç­‰å¾…ç”¨æˆ·é€‰æ‹©")
            @unknown default:
                print("ğŸ“ æœªçŸ¥çš„ä½ç½®æƒé™çŠ¶æ€: \(status.rawValue)")
            }
        }
    }
}

// MARK: - AVCapturePhotoCaptureDelegate
extension CameraManager: AVCapturePhotoCaptureDelegate {
    nonisolated func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            Task { @MainActor in self.photoDataHandler?(nil) }
            print("âŒ [ç…§ç‰‡] æ‹æ‘„é”™è¯¯: \(error)")
            return
        }
        guard let imageData = photo.fileDataRepresentation() else {
            Task { @MainActor in self.photoDataHandler?(nil) }
            print("âŒ [ç…§ç‰‡] æ— æ³•è·å–ç…§ç‰‡æ•°æ®")
            return
        }

        Task.detached(priority: .userInitiated) {
            // åŸå§‹ç…§ç‰‡ä¿¡æ¯
            if let source = CGImageSourceCreateWithData(imageData as CFData, nil),
               let props = CGImageSourceCopyPropertiesAtIndex(source, 0, nil) as? [String: Any] {
                let width = props[kCGImagePropertyPixelWidth as String] as? Int ?? 0
                let height = props[kCGImagePropertyPixelHeight as String] as? Int ?? 0
                let exifOrientation = props[kCGImagePropertyOrientation as String] as? UInt32 ?? 0
                print("ğŸ“¸ [ç…§ç‰‡] åŸå§‹å°ºå¯¸: \(width)Ã—\(height), EXIFæ–¹å‘: \(exifOrientation)")
            }

            // è¯»å–ç…§ç‰‡çš„ EXIF æ–¹å‘å¹¶ç‰©ç†æ—‹è½¬åƒç´ 
            let rotatedData = self.applyExifOrientationToPixels(imageData: imageData)

            // è°ƒè¯•æ—¥å¿—
            if let rotatedData = rotatedData,
               let source = CGImageSourceCreateWithData(rotatedData as CFData, nil),
               let props = CGImageSourceCopyPropertiesAtIndex(source, 0, nil) as? [String: Any] {
                let width = props[kCGImagePropertyPixelWidth as String] as? Int ?? 0
                let height = props[kCGImagePropertyPixelHeight as String] as? Int ?? 0
                let exifOrientation = props[kCGImagePropertyOrientation as String] as? UInt32 ?? 0
                print("ğŸ“¸ [ç…§ç‰‡] æ—‹è½¬åå°ºå¯¸: \(width)Ã—\(height), EXIFæ–¹å‘: \(exifOrientation)")
            }

            // å›è°ƒå¤„ç†åçš„æ•°æ®
            await MainActor.run {
                self.photoDataHandler?(rotatedData ?? imageData)
            }
        }

        // æ‹ç…§å®Œæˆåæ¢å¤æ›å…‰
        Task { @MainActor in
            if let device = self.videoCaptureDevice {
                do {
                    try device.lockForConfiguration()
                    device.setExposureTargetBias(self.previousExposureTargetBias) { _ in }
                    if self.lockedExposureForFlashCapture, device.isExposureModeSupported(.continuousAutoExposure) {
                        device.exposureMode = .continuousAutoExposure
                        self.lockedExposureForFlashCapture = false
                    }
                    device.unlockForConfiguration()
                } catch {}
            }
        }
    }

    /// è¯»å–ç…§ç‰‡ EXIF æ–¹å‘å¹¶ç‰©ç†æ—‹è½¬åƒç´ 
    /// AVFoundation æ‹æ‘„çš„ç…§ç‰‡å¸¦æœ‰ EXIF æ–¹å‘æ ‡è®°ï¼Œæˆ‘ä»¬å°†å…¶åº”ç”¨åˆ°åƒç´ ä¸Š
    private nonisolated func applyExifOrientationToPixels(imageData: Data) -> Data? {
        // 1. è¯»å– EXIF æ–¹å‘
        guard let imageSource = CGImageSourceCreateWithData(imageData as CFData, nil),
              let properties = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, nil) as? [String: Any] else {
            return imageData
        }

        // è·å–æ–¹å‘å€¼ï¼ˆé»˜è®¤ä¸º 1 = .upï¼‰
        let orientationValue = properties[kCGImagePropertyOrientation as String] as? UInt32 ?? 1
        let orientation = CGImagePropertyOrientation(rawValue: orientationValue) ?? .up

        print("ğŸ“¸ [ç…§ç‰‡] EXIF æ–¹å‘å€¼: \(orientationValue)")

        // å¦‚æœæ–¹å‘å·²ç»æ˜¯ .upï¼Œæ— éœ€æ—‹è½¬
        if orientation == .up {
            return imageData
        }

        // 2. åŠ è½½å›¾åƒå¹¶åº”ç”¨æ–¹å‘
        guard let ciImage = CIImage(data: imageData) else { return imageData }
        let rotatedImage = ciImage.oriented(orientation)

        // 3. æ¸²æŸ“ä¸º JPEG
        let ciContext = CIContext()
        let colorSpace = CGColorSpace(name: CGColorSpace.sRGB) ?? CGColorSpaceCreateDeviceRGB()

        guard let renderedJPEG = ciContext.jpegRepresentation(of: rotatedImage, colorSpace: colorSpace, options: [
            kCGImageDestinationLossyCompressionQuality as CIImageRepresentationOption: 0.95
        ]) else { return imageData }

        // 4. å¤åˆ¶å…ƒæ•°æ®ï¼Œå¹¶å°†æ–¹å‘è®¾ä¸º .up
        var metadata = properties
        metadata[kCGImagePropertyOrientation as String] = 1
        if var tiff = metadata[kCGImagePropertyTIFFDictionary as String] as? [String: Any] {
            tiff[kCGImagePropertyTIFFOrientation as String] = 1
            metadata[kCGImagePropertyTIFFDictionary as String] = tiff
        }

        // 5. å†™å…¥æœ€ç»ˆå›¾åƒ
        guard let renderedSource = CGImageSourceCreateWithData(renderedJPEG as CFData, nil),
              let mutableData = CFDataCreateMutable(nil, 0),
              let imageType = CGImageSourceGetType(renderedSource),
              let destination = CGImageDestinationCreateWithData(mutableData, imageType, 1, nil) else {
            return imageData
        }

        metadata[kCGImageDestinationLossyCompressionQuality as String] = 0.95
        CGImageDestinationAddImageFromSource(destination, renderedSource, 0, metadata as CFDictionary)

        guard CGImageDestinationFinalize(destination) else { return imageData }

        let rotatedExtent = rotatedImage.extent
        print("ğŸ“¸ [ç…§ç‰‡] æ—‹è½¬åå°ºå¯¸: \(Int(rotatedExtent.width))Ã—\(Int(rotatedExtent.height))")

        return mutableData as Data
    }
}

// MARK: - è§†é¢‘è¾“å‡ºï¼šå®æ—¶é¢„è§ˆåƒç´ ç¼“å­˜
extension CameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    @preconcurrency nonisolated func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let buffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        Task { @MainActor in
            self.latestPixelBuffer = buffer
        }
    }
}

// MARK: - SwiftUI å®æ—¶é¢„è§ˆè§†å›¾ï¼ˆMTKView + CI æ¸²æŸ“ï¼‰
struct RealtimePreviewView: UIViewRepresentable {
    let manager: CameraManager
    let preset: FilmPreset

    func makeUIView(context: Context) -> MTKView {
        let view = MTKView(frame: .zero, device: MTLCreateSystemDefaultDevice())
        view.isPaused = false
        view.enableSetNeedsDisplay = false
        view.framebufferOnly = false
        view.preferredFramesPerSecond = 30
        // æ¸…é™¤èƒŒæ™¯è‰²
        view.clearColor = MTLClearColor(red: 0, green: 0, blue: 0, alpha: 1)
        context.coordinator.setup(view: view)
        return view
    }

    func updateUIView(_ uiView: MTKView, context: Context) {
        context.coordinator.preset = preset
        context.coordinator.manager = manager
    }

    func makeCoordinator() -> Coordinator {
        Coordinator()
    }

    final class Coordinator: NSObject, MTKViewDelegate {
        var preset: FilmPreset = .fujiC200
        weak var manager: CameraManager?
        private var ciContext: CIContext!
        private var commandQueue: MTLCommandQueue?
        // æ—¥å¿—èŠ‚æµ
        private var lastLogTime: Date = .distantPast
        private let logInterval: TimeInterval = 2.0

        func setup(view: MTKView) {
            view.delegate = self
            if let device = view.device {
                commandQueue = device.makeCommandQueue()
                ciContext = CIContext(mtlDevice: device, options: [
                    .workingColorSpace: CGColorSpaceCreateDeviceRGB(),
                    .outputColorSpace: CGColorSpaceCreateDeviceRGB()
                ])
            }
        }

        func mtkView(_ view: MTKView, drawableSizeWillChange size: CGSize) {}

        func draw(in view: MTKView) {
            guard let pixelBuffer = manager?.latestPixelBuffer,
                  let drawable = view.currentDrawable,
                  let commandBuffer = commandQueue?.makeCommandBuffer() else { return }

            // 1. ä»ç›¸æœºè·å–åŸå§‹å›¾åƒ
            var ciImage = CIImage(cvPixelBuffer: pixelBuffer)
            let rawExtent = ciImage.extent

            // 2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬
            // ç›¸æœºé¢„è§ˆåº”è¯¥æ˜¯ç«–å±ï¼ˆé«˜ > å®½ï¼‰ï¼Œå¦‚æœæ˜¯æ¨ªå‘bufferï¼ˆå®½ > é«˜ï¼‰ï¼Œéœ€è¦æ—‹è½¬90åº¦
            let isLandscapeBuffer = rawExtent.width > rawExtent.height
            let drawableSize = CGSize(width: drawable.texture.width, height: drawable.texture.height)
            let isPortraitView = drawableSize.height > drawableSize.width

            // å¦‚æœ buffer æ˜¯æ¨ªå‘çš„ï¼Œä½†è§†å›¾æ˜¯ç«–å‘çš„ï¼Œéœ€è¦æ—‹è½¬
            if isLandscapeBuffer && isPortraitView {
                // å¼ºåˆ¶æ—‹è½¬ 90 åº¦ä½¿å…¶å˜ä¸ºç«–å‘
                ciImage = ciImage.oriented(.right)
            } else if let angle = manager?.previewRotationAngle, angle != 0 {
                // å¦åˆ™ä½¿ç”¨ RotationCoordinator æä¾›çš„è§’åº¦
                let orientation = orientationFromAngle(angle)
                ciImage = ciImage.oriented(orientation)
            }

            // 3. åº”ç”¨ LUT æ»¤é•œ
            let lutImage = FilmProcessor.shared.applyLUT(to: ciImage, preset: preset) ?? ciImage
            let imageExtent = lutImage.extent

            // 4. è®¡ç®—å¡«å……æ¸²æŸ“åŒºåŸŸï¼ˆä¿æŒæ¯”ä¾‹ï¼Œå±…ä¸­æ˜¾ç¤ºï¼‰
            let targetRect = aspectFillRect(imageSize: imageExtent.size, targetSize: drawableSize)

            // 5. å°†å›¾åƒç¼©æ”¾åˆ°ç›®æ ‡åŒºåŸŸ
            let scaleX = targetRect.width / imageExtent.width
            let scaleY = targetRect.height / imageExtent.height
            let scaledImage = lutImage
                .transformed(by: CGAffineTransform(scaleX: scaleX, y: scaleY))
                .transformed(by: CGAffineTransform(translationX: targetRect.origin.x, y: targetRect.origin.y))

            // 6. æ¸²æŸ“åˆ° drawable
            let renderBounds = CGRect(origin: .zero, size: drawableSize)
            ciContext.render(scaledImage, to: drawable.texture, commandBuffer: commandBuffer, bounds: renderBounds, colorSpace: CGColorSpaceCreateDeviceRGB())
            commandBuffer.present(drawable)
            commandBuffer.commit()

            // èŠ‚æµæ—¥å¿—
            let now = Date()
            if now.timeIntervalSince(lastLogTime) >= logInterval {
                lastLogTime = now
                let rotationAngle = manager?.previewRotationAngle ?? -1
                let autoRotated = isLandscapeBuffer && isPortraitView
                print("ğŸ¥ [é¢„è§ˆ] åŸå§‹:\(Int(rawExtent.width))Ã—\(Int(rawExtent.height)) è‡ªåŠ¨æ—‹è½¬:\(autoRotated) è§’åº¦:\(Int(rotationAngle))Â° â†’ å¤„ç†å:\(Int(imageExtent.width))Ã—\(Int(imageExtent.height)) â†’ æ˜¾ç¤º:\(Int(targetRect.width))Ã—\(Int(targetRect.height))")
            }
        }

        // è§’åº¦è½¬æ–¹å‘
        private func orientationFromAngle(_ angle: CGFloat) -> CGImagePropertyOrientation {
            let normalized = Int(angle.truncatingRemainder(dividingBy: 360))
            switch normalized {
            case 0: return .up
            case 90: return .right
            case 180: return .down
            case 270: return .left
            default: return .up
            }
        }

        // è®¡ç®— Aspect Fill åŒºåŸŸï¼ˆå±…ä¸­ï¼Œä¿æŒæ¯”ä¾‹ï¼Œå¡«æ»¡ç›®æ ‡ï¼‰
        private func aspectFillRect(imageSize: CGSize, targetSize: CGSize) -> CGRect {
            let imageAspect = imageSize.width / imageSize.height
            let targetAspect = targetSize.width / targetSize.height

            var drawWidth: CGFloat
            var drawHeight: CGFloat

            if imageAspect > targetAspect {
                // å›¾åƒæ›´å®½ï¼ŒæŒ‰é«˜åº¦å¡«æ»¡
                drawHeight = targetSize.height
                drawWidth = drawHeight * imageAspect
            } else {
                // å›¾åƒæ›´é«˜ï¼ŒæŒ‰å®½åº¦å¡«æ»¡
                drawWidth = targetSize.width
                drawHeight = drawWidth / imageAspect
            }

            let x = (targetSize.width - drawWidth) / 2
            let y = (targetSize.height - drawHeight) / 2

            return CGRect(x: x, y: y, width: drawWidth, height: drawHeight)
        }
    }
}

// MARK: - UIDeviceOrientation Extension
extension UIDeviceOrientation {
    var isValidInterfaceOrientation: Bool {
        switch self {
        case .portrait, .portraitUpsideDown, .landscapeLeft, .landscapeRight:
            return true
        default:
            return false
        }
    }
} 


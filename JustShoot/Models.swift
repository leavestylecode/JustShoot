import Foundation
import SwiftData
import UIKit
import ImageIO
import CoreImage
import CoreImage.CIFilterBuiltins
import CoreLocation

@Model
final class Photo: Identifiable {
    var id: UUID
    var timestamp: Date
    @Attribute(.externalStorage) var imageData: Data
    var filmPresetName: String?
    @Relationship(inverse: \Roll.photos) var roll: Roll?
    // ä½ç½®ä¿¡æ¯ï¼ˆç”¨äºŽç›¸å†Œä¿å­˜æ—¶åŒæ­¥åˆ° PHAsset.locationï¼‰
    var latitude: Double?
    var longitude: Double?
    var altitude: Double?
    var locationTimestamp: Date?
    
    init(imageData: Data, filmPresetName: String? = nil) {
        self.id = UUID()
        self.timestamp = Date()
        self.imageData = imageData
        self.filmPresetName = filmPresetName
    }
    
    var image: UIImage? {
        return UIImage(data: imageData)
    }
    
    // EXIF æ•°æ®æå–
    var exifData: [String: Any]? {
        guard let imageSource = CGImageSourceCreateWithData(imageData as CFData, nil),
              let properties = CGImageSourceCopyPropertiesAtIndex(imageSource, 0, nil) as? [String: Any] else {
            return nil
        }
        return properties
    }
    
    // èŽ·å–ç‰¹å®šçš„EXIFä¿¡æ¯
    var iso: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let isoValue = exif[kCGImagePropertyExifISOSpeedRatings as String] as? [NSNumber],
              let iso = isoValue.first else {
            return "æœªçŸ¥"
        }
        return "ISO \(iso)"
    }
    
    var shutterSpeed: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let exposureTime = exif[kCGImagePropertyExifExposureTime as String] as? Double else {
            return "æœªçŸ¥"
        }
        
        if exposureTime >= 1 {
            return String(format: "%.1fs", exposureTime)
        } else {
            return "1/\(Int(1/exposureTime))s"
        }
    }
    
    var aperture: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let fNumber = exif[kCGImagePropertyExifFNumber as String] as? Double else {
            return "æœªçŸ¥"
        }
        return String(format: "f/%.1f", fNumber)
    }
    
    var focalLength: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any] else {
            return "æœªçŸ¥"
        }
        
        // ä¼˜å…ˆä½¿ç”¨35mmç­‰æ•ˆç„¦è·
        if let focalLength35mm = exif[kCGImagePropertyExifFocalLenIn35mmFilm as String] as? Int {
            return "\(focalLength35mm)mm"
        }
        
        // å¦‚æžœæ²¡æœ‰35mmç­‰æ•ˆç„¦è·ï¼Œä½¿ç”¨å®žé™…ç‰©ç†ç„¦è·
        if let focal = exif[kCGImagePropertyExifFocalLength as String] as? Double {
            return String(format: "%.0fmm", focal)
        }
        
        return "æœªçŸ¥"
    }
    
    var exposureMode: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let exposureMode = exif[kCGImagePropertyExifExposureMode as String] as? Int else {
            return "æœªçŸ¥"
        }
        
        switch exposureMode {
        case 0: return "è‡ªåŠ¨æ›å…‰"
        case 1: return "æ‰‹åŠ¨æ›å…‰"
        case 2: return "è‡ªåŠ¨åŒ…å›´æ›å…‰"
        default: return "æœªçŸ¥"
        }
    }
    
    var flashMode: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any],
              let flash = exif[kCGImagePropertyExifFlash as String] as? Int else {
            return "æœªçŸ¥"
        }
        
        if flash & 0x01 != 0 {
            return "é—ªå…‰ç¯å¼€å¯"
        } else {
            return "é—ªå…‰ç¯å…³é—­"
        }
    }
    
    // GPSä¿¡æ¯
    var gpsInfo: (latitude: String, longitude: String, altitude: String)? {
        guard let gpsDict = exifData?[kCGImagePropertyGPSDictionary as String] as? [String: Any],
              let lat = gpsDict[kCGImagePropertyGPSLatitude as String] as? Double,
              let latRef = gpsDict[kCGImagePropertyGPSLatitudeRef as String] as? String,
              let lon = gpsDict[kCGImagePropertyGPSLongitude as String] as? Double,
              let lonRef = gpsDict[kCGImagePropertyGPSLongitudeRef as String] as? String else {
            return nil
        }
        
        let altitude = gpsDict[kCGImagePropertyGPSAltitude as String] as? Double ?? 0
        
        return (
            latitude: String(format: "%.6fÂ°%@", lat, latRef),
            longitude: String(format: "%.6fÂ°%@", lon, lonRef),
            altitude: String(format: "%.1fm", altitude)
        )
    }
    
    // è®¾å¤‡ä¿¡æ¯
    var deviceInfo: (make: String, model: String, software: String)? {
        let tiffDict = exifData?[kCGImagePropertyTIFFDictionary as String] as? [String: Any]
        
        let make = tiffDict?[kCGImagePropertyTIFFMake as String] as? String ?? "æœªçŸ¥"
        let model = tiffDict?[kCGImagePropertyTIFFModel as String] as? String ?? "æœªçŸ¥"
        let software = tiffDict?[kCGImagePropertyTIFFSoftware as String] as? String ?? "æœªçŸ¥"
        
        return (make: make, model: model, software: software)
    }
    
    // é•œå¤´ä¿¡æ¯
    var lensInfo: String {
        guard let exif = exifData?[kCGImagePropertyExifDictionary as String] as? [String: Any] else {
            return "æœªçŸ¥é•œå¤´"
        }
        
        // å°è¯•ä»Žä¸åŒçš„EXIFå­—æ®µèŽ·å–é•œå¤´ä¿¡æ¯
        if let lensModel = exif["LensModel"] as? String {
            return lensModel
        }
        
        if let lensMake = exif["LensMake"] as? String {
            return lensMake
        }
        
        // å¦‚æžœæ²¡æœ‰ä¸“é—¨çš„é•œå¤´ä¿¡æ¯ï¼Œè¿”å›žç›¸æœºåž‹å·ä½œä¸ºé•œå¤´ä¿¡æ¯
        if let deviceInfo = deviceInfo {
            return "\(deviceInfo.make) \(deviceInfo.model) å†…ç½®é•œå¤´"
        }
        
        return "å†…ç½®é•œå¤´"
    }
} 

// MARK: - èƒ¶ç‰‡é¢„è®¾ä¸Žå¤„ç†
enum FilmPreset: String, CaseIterable, Identifiable, Sendable {
    case fujiC200
    case fujiPro400H
    case fujiProvia100F
    case kodakPortra400
    case kodakVision5219 // 500T
    case kodakVision5203 // 50D
    case kodak5207       // 250Dï¼ˆæ–‡ä»¶åæ—  Vision å‰ç¼€ï¼‰
    case harmanPhoenix200

    var id: String { rawValue }

    var displayName: String {
        switch self {
        case .fujiC200: return "Fuji C200"
        case .fujiPro400H: return "Fuji Pro 400H"
        case .fujiProvia100F: return "Fuji Provia 100F"
        case .kodakPortra400: return "Kodak Portra 400"
        case .kodakVision5219: return "Kodak Vision3 500T (5219)"
        case .kodakVision5203: return "Kodak Vision3 50D (5203)"
        case .kodak5207: return "Kodak 250D (5207)"
        case .harmanPhoenix200: return "Harman Phoenix 200"
        }
    }

    var iso: Float {
        switch self {
        case .fujiC200: return 200
        case .fujiPro400H: return 400
        case .fujiProvia100F: return 100
        case .kodakPortra400: return 400
        case .kodakVision5219: return 500
        case .kodakVision5203: return 50
        case .kodak5207: return 250
        case .harmanPhoenix200: return 200
        }
    }

    // èµ„æºæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
    var lutResourceName: String {
        switch self {
        case .fujiC200: return "FujiC200"
        case .fujiPro400H: return "FujiPro400H"
        case .fujiProvia100F: return "FujiProvia100F"
        case .kodakPortra400: return "KodakPortra400"
        case .kodakVision5219: return "KodakVision5219"
        case .kodakVision5203: return "KodakVision5203"
        case .kodak5207: return "Kodak5207"
        case .harmanPhoenix200: return "HarmanPhoenix200"
        }
    }
}

extension Photo {
    var filmPreset: FilmPreset? {
        guard let name = filmPresetName else { return nil }
        return FilmPreset(rawValue: name)
    }
    
    var filmDisplayName: String {
        filmPreset?.displayName ?? "é»˜è®¤"
    }
}

struct CubeLUT {
    let data: Data
    let dimension: Int
}

// MARK: - èƒ¶å·åˆ†ç»„ï¼ˆ27å¼ ä¸€ç»„ï¼‰
@Model
final class Roll: Identifiable {
    var id: UUID
    var createdAt: Date
    var completedAt: Date?
    var presetName: String
    var capacity: Int
    @Relationship var photos: [Photo]

    init(preset: FilmPreset, capacity: Int = 27) {
        self.id = UUID()
        self.createdAt = Date()
        self.presetName = preset.rawValue
        self.capacity = capacity
        self.photos = []
    }

    var preset: FilmPreset? { FilmPreset(rawValue: presetName) }
    var displayName: String { preset?.displayName ?? presetName }
    var shotsTaken: Int { photos.count }
    var exposuresRemaining: Int { max(0, capacity - shotsTaken) }
    var isCompleted: Bool { completedAt != nil || shotsTaken >= capacity }
}

final class FilmProcessor {
    static let shared = FilmProcessor()

    private let ciContext: CIContext
    private var lutCache: [String: CubeLUT] = [:]

    private init() {
        // ä½¿ç”¨ Metal åŽç«¯ + sRGB è‰²å½©ç©ºé—´ï¼ˆä¸Žé¢„è§ˆä¿æŒä¸€è‡´ï¼‰
        let srgbColorSpace = CGColorSpace(name: CGColorSpace.sRGB) ?? CGColorSpaceCreateDeviceRGB()
        self.ciContext = CIContext(options: [
            CIContextOption.useSoftwareRenderer: false,
            CIContextOption.workingColorSpace: srgbColorSpace,
            CIContextOption.outputColorSpace: srgbColorSpace
        ])
    }

    func loadCubeLUT(resourceName: String) throws -> CubeLUT {
        if let cached = lutCache[resourceName] { return cached }

        guard let url = Bundle.main.url(forResource: resourceName, withExtension: "cube") else {
            throw NSError(domain: "FilmProcessor", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ‰¾ä¸åˆ° LUT èµ„æº: \(resourceName).cube"])
        }

        let text = try String(contentsOf: url, encoding: .utf8)
        var lines = text.split(whereSeparator: \.isNewline).map { $0.trimmingCharacters(in: .whitespaces) }
        lines.removeAll { $0.hasPrefix("#") || $0.isEmpty }

        var size = 0
        var values: [Float] = []

        for line in lines {
            if line.uppercased().hasPrefix("LUT_3D_SIZE") {
                if let last = line.split(separator: " ").last, let dim = Int(last) {
                    size = dim
                }
            } else {
                // ç²—ç•¥åˆ¤æ–­æ˜¯å¦ä¸ºæ•°å€¼è¡Œ
                let comps = line.split(separator: " ").compactMap { Float($0) }
                if comps.count == 3 {
                    values.append(contentsOf: comps)
                }
            }
        }

        guard size > 0, values.count == size * size * size * 3 else {
            throw NSError(domain: "FilmProcessor", code: -2, userInfo: [NSLocalizedDescriptionKey: "LUT è§£æžå¤±è´¥æˆ–å°ºå¯¸ä¸åŒ¹é…"])
        }

        var rgba: [Float] = []
        rgba.reserveCapacity(size * size * size * 4)
        for i in stride(from: 0, to: values.count, by: 3) {
            rgba.append(values[i + 0])
            rgba.append(values[i + 1])
            rgba.append(values[i + 2])
            rgba.append(1.0)
        }

        // å®‰å…¨æž„é€  Dataï¼Œé¿å…æ‚¬åž‚æŒ‡é’ˆ
        let data: Data = rgba.withUnsafeBufferPointer { buffer in
            return Data(buffer: buffer)
        }
        let cube = CubeLUT(
            data: data,
            dimension: size
        )
        lutCache[resourceName] = cube
        return cube
    }

    // é¢„åŠ è½½ï¼ˆæ”¾åˆ°ç¼“å­˜ï¼‰ï¼Œå‡å°‘é¦–æ¬¡æ‹æ‘„å¼€é”€
    func preload(preset: FilmPreset) {
        _ = try? loadCubeLUT(resourceName: preset.lutResourceName)
    }

    func applyLUT(to inputData: Data, preset: FilmPreset, outputQuality: CGFloat = 0.95) -> Data? {
        guard let ciInput = CIImage(data: inputData) else { return nil }
        guard let colorCube = CIFilter(name: "CIColorCube") else { return nil }

        do {
            let lut = try loadCubeLUT(resourceName: preset.lutResourceName)
            colorCube.setValue(ciInput, forKey: kCIInputImageKey)
            colorCube.setValue(lut.dimension, forKey: "inputCubeDimension")
            colorCube.setValue(lut.data, forKey: "inputCubeData")
        } catch {
            return nil
        }

        guard let output = colorCube.outputImage else { return nil }

        // æ¸²æŸ“ä¸º JPEG æ•°æ®
        let colorSpace = CGColorSpace(name: CGColorSpace.displayP3) ?? CGColorSpaceCreateDeviceRGB()
        if let data = ciContext.jpegRepresentation(of: output, colorSpace: colorSpace, options: [kCGImageDestinationLossyCompressionQuality as CIImageRepresentationOption: outputQuality]) {
            return data as Data
        }
        return nil
    }

    /// åº”ç”¨ LUT å¹¶ä¿ç•™/æ·»åŠ å…ƒæ•°æ®
    /// - Parameters:
    ///   - imageData: å·²ç‰©ç†æ—‹è½¬çš„ç…§ç‰‡æ•°æ®ï¼ˆåƒç´ æ–¹å‘æ­£ç¡®ï¼Œæ— éœ€å†è¯» EXIF æ—‹è½¬ï¼‰
    ///   - preset: èƒ¶ç‰‡é¢„è®¾
    ///   - outputQuality: JPEG åŽ‹ç¼©è´¨é‡
    ///   - location: GPS ä½ç½®ï¼ˆå¯é€‰ï¼‰
    /// - Returns: å¤„ç†åŽçš„ç…§ç‰‡æ•°æ®
    func applyLUTPreservingMetadata(imageData: Data, preset: FilmPreset, outputQuality: CGFloat = 0.95, location: CLLocation? = nil) -> Data? {
        // 1. åŠ è½½å›¾åƒï¼ˆç…§ç‰‡å·²ç‰©ç†æ—‹è½¬ï¼Œç›´æŽ¥ä½¿ç”¨ï¼‰
        guard var ciInput = CIImage(data: imageData) else {
            print("âŒ [LUT] æ— æ³•ä»Žæ•°æ®åˆ›å»º CIImage")
            return nil
        }

        let inputExtent = ciInput.extent
        let isLandscape = inputExtent.width > inputExtent.height
        print("ðŸŽ¨ [LUT] åŽŸå§‹å°ºå¯¸: \(Int(inputExtent.width))Ã—\(Int(inputExtent.height)) \(isLandscape ? "æ¨ªå‘" : "ç«–å‘")")

        // 2. æ ¹æ®ç…§ç‰‡æ–¹å‘è£å‰ªä¸ºå¯¹åº”æ¯”ä¾‹ï¼ˆæ¨ªæ‹4:3ï¼Œç«–æ‹3:4ï¼‰
        // é¢„è§ˆå–æ™¯æ¡†æ˜¯ 3:4 ç«–å±ï¼Œä½†ç›¸æœºå¯ä»¥æ¨ªç€æ‹ï¼ˆæ­¤æ—¶ç…§ç‰‡æ˜¯æ¨ªå‘çš„ï¼‰
        let targetAspect: CGFloat = isLandscape ? (4.0 / 3.0) : (3.0 / 4.0)
        let currentAspect = inputExtent.width / inputExtent.height

        var cropRect = inputExtent
        if abs(currentAspect - targetAspect) > 0.01 {
            if currentAspect > targetAspect {
                // å›¾ç‰‡å¤ªå®½ï¼Œè£å‰ªå·¦å³ä¸¤è¾¹
                let newWidth = inputExtent.height * targetAspect
                let xOffset = (inputExtent.width - newWidth) / 2
                cropRect = CGRect(x: inputExtent.origin.x + xOffset, y: inputExtent.origin.y, width: newWidth, height: inputExtent.height)
            } else {
                // å›¾ç‰‡å¤ªé«˜ï¼Œè£å‰ªä¸Šä¸‹ä¸¤è¾¹
                let newHeight = inputExtent.width / targetAspect
                let yOffset = (inputExtent.height - newHeight) / 2
                cropRect = CGRect(x: inputExtent.origin.x, y: inputExtent.origin.y + yOffset, width: inputExtent.width, height: newHeight)
            }
            ciInput = ciInput.cropped(to: cropRect)
            print("âœ‚ï¸ [LUT] è£å‰ªä¸º \(isLandscape ? "4:3" : "3:4"): \(Int(cropRect.width))Ã—\(Int(cropRect.height))")
        }

        // 3. åº”ç”¨ LUT æ»¤é•œ
        guard let colorCube = CIFilter(name: "CIColorCube") else {
            print("âŒ [LUT] æ— æ³•åˆ›å»º CIColorCube æ»¤é•œ")
            return nil
        }

        do {
            let lut = try loadCubeLUT(resourceName: preset.lutResourceName)
            colorCube.setValue(ciInput, forKey: kCIInputImageKey)
            colorCube.setValue(lut.dimension, forKey: "inputCubeDimension")
            colorCube.setValue(lut.data, forKey: "inputCubeData")
        } catch {
            print("âŒ [LUT] åŠ è½½ LUT å¤±è´¥: \(error)")
            return nil
        }

        guard let output = colorCube.outputImage else {
            print("âŒ [LUT] æ— æ³•ç”Ÿæˆè¾“å‡ºå›¾åƒ")
            return nil
        }

        let outputExtent = output.extent
        print("âœ… [LUT] è¾“å‡ºå°ºå¯¸: \(Int(outputExtent.width))Ã—\(Int(outputExtent.height))")

        // 3. æ¸²æŸ“ä¸º JPEG
        let colorSpace = CGColorSpace(name: CGColorSpace.sRGB) ?? CGColorSpaceCreateDeviceRGB()
        guard let renderedJPEG = ciContext.jpegRepresentation(
            of: output,
            colorSpace: colorSpace,
            options: [kCGImageDestinationLossyCompressionQuality as CIImageRepresentationOption: outputQuality]
        ) else {
            print("âŒ [LUT] æ¸²æŸ“ JPEG å¤±è´¥")
            return nil
        }

        // 4. æå–åŽŸå§‹å…ƒæ•°æ®
        guard let originalSource = CGImageSourceCreateWithData(imageData as CFData, nil) else { return nil }
        var metadata = CGImageSourceCopyPropertiesAtIndex(originalSource, 0, nil) as? [String: Any] ?? [:]

        // 5. ç¡®ä¿æ–¹å‘æ ‡è®°ä¸º .upï¼ˆå› ä¸ºåƒç´ å·²ç‰©ç†æ—‹è½¬ï¼‰
        metadata[kCGImagePropertyOrientation as String] = 1
        if var tiff = metadata[kCGImagePropertyTIFFDictionary as String] as? [String: Any] {
            tiff[kCGImagePropertyTIFFOrientation as String] = 1
            metadata[kCGImagePropertyTIFFDictionary as String] = tiff
        }

        // 6. æ·»åŠ  GPS ä¿¡æ¯
        if let loc = location {
            var gps: [String: Any] = metadata[kCGImagePropertyGPSDictionary as String] as? [String: Any] ?? [:]
            gps[kCGImagePropertyGPSLatitude as String] = abs(loc.coordinate.latitude)
            gps[kCGImagePropertyGPSLongitude as String] = abs(loc.coordinate.longitude)
            gps[kCGImagePropertyGPSLatitudeRef as String] = loc.coordinate.latitude >= 0 ? "N" : "S"
            gps[kCGImagePropertyGPSLongitudeRef as String] = loc.coordinate.longitude >= 0 ? "E" : "W"
            gps[kCGImagePropertyGPSAltitude as String] = abs(loc.altitude)
            gps[kCGImagePropertyGPSAltitudeRef as String] = loc.altitude >= 0 ? 0 : 1

            let utc = TimeZone(secondsFromGMT: 0)
            let dateFmt = DateFormatter(); dateFmt.dateFormat = "yyyy:MM:dd"; dateFmt.timeZone = utc
            let timeFmt = DateFormatter(); timeFmt.dateFormat = "HH:mm:ss.SS"; timeFmt.timeZone = utc
            gps[kCGImagePropertyGPSDateStamp as String] = dateFmt.string(from: loc.timestamp)
            gps[kCGImagePropertyGPSTimeStamp as String] = timeFmt.string(from: loc.timestamp)

            if loc.speed >= 0 {
                gps[kCGImagePropertyGPSSpeed as String] = loc.speed * 3.6
                gps[kCGImagePropertyGPSSpeedRef as String] = "K"
            }
            if loc.course >= 0 {
                gps[kCGImagePropertyGPSImgDirection as String] = loc.course
                gps[kCGImagePropertyGPSImgDirectionRef as String] = "T"
            }
            metadata[kCGImagePropertyGPSDictionary as String] = gps
        }

        // 7. å†™å…¥æœ€ç»ˆå›¾åƒ
        guard let renderedSource = CGImageSourceCreateWithData(renderedJPEG as CFData, nil),
              let mutableData = CFDataCreateMutable(nil, 0),
              let imageType = CGImageSourceGetType(renderedSource),
              let destination = CGImageDestinationCreateWithData(mutableData, imageType, 1, nil) else {
            return nil
        }

        metadata[kCGImageDestinationLossyCompressionQuality as String] = outputQuality
        CGImageDestinationAddImageFromSource(destination, renderedSource, 0, metadata as CFDictionary)

        guard CGImageDestinationFinalize(destination) else { return nil }
        return mutableData as Data
    }

    // å®žæ—¶é¢„è§ˆï¼šå¯¹ CIImage ç›´æŽ¥åº”ç”¨ LUTï¼Œè¿”å›ž CIImageï¼ˆç”¨äºŽ GPU ç®¡çº¿ï¼‰
    func applyLUT(to image: CIImage, preset: FilmPreset) -> CIImage? {
        guard let colorCube = CIFilter(name: "CIColorCube") else { return nil }
        do {
            let lut = try loadCubeLUT(resourceName: preset.lutResourceName)
            colorCube.setValue(image, forKey: kCIInputImageKey)
            colorCube.setValue(lut.dimension, forKey: "inputCubeDimension")
            colorCube.setValue(lut.data, forKey: "inputCubeData")
            return colorCube.outputImage
        } catch {
            return nil
        }
    }
}